PETER R. DAVIES,1 H. SCOTT HURD,2 JULIE A. FUNK,3 PAULA J. FEDORKA-CRAY,4 and FRANK T. JONES5
ABSTRACT 
Food animal producers have ethical obligations to reduce the risk of foodborne hazards in animals under their care . 
Contaminated feed is a recognized source of Salmonella infection of food animals and regulations to control Salmonella contamination of animal feed have existed in some countries for decades . 
The impact of reducing Sal-monella contamination of animal feeds on the risk of human foodborne salmonellosis is difficult to assess , and is likely to vary among food animal industries . 
In the context of U.S. pork production , factors that may attenuate or negate the impact ( on public health ) of regulatory interventions to control Salmonella in commercial feed include widespread use of on-farm mixing of swine feed ; incomplete decontamination of feed during processing ; post-processing contamination of feed at feed mills or in transportation or on-farm storage ; the multitude of nonfeed sources of Salmonella infection ; an apparently high risk of post-farm infection in lairage ; and post-harvest sources of contamination . 
A structured survey of the extent of Salmonella contamination of animal feed in the United States is necessary to enable more informed debate on the feasibility and likely efficacy of enforcing a Salmonella-negative standard for animal feeds to reduce the incidence of human salmonellosis . 
INTRODUCTION
FOOD SAFETY is critical to consumer confidence in the food supply and the prosperity of food producing enterprises . 
For meat industries , the 1990s brought revolutionary changes in both regulations and consumer attitudes towards food safety which drew attention to the responsibilities of the animal production sector to reduce the risk of foodborne illness . 
The `` farm-to-table '' concept ( where all participants in food production and consumption bear responsibilities for reducing the risk of foodborne disease ) is now the accepted par-adigm for addressing food safety . 
However , for many hazards , meaningful analysis of how the farm-to-table paradigm should be realized is lacking . 
Conceptually , we can view the food supply continuum as a linear series of sectors engaged in production , harvest , distribution , and consumption . 
Within any sector measures can be applied to reduce risk of foodborne hazards , and the goal is to define the optimal mix of interventions across the continuum that delivers maximum risk reduction at minimal cost . 
A recent review of the relationship between contamination of animal feed and human foodborne illness proposed that a Salmonella-nega-tive policy for animal feed should be enforced ( Crump et al. , 2002 ) . 
We discuss this strategy for reducing the incidence of human salmonellosis in the context of current understanding of the epidemiology of Salmonella in pork production . 
PREHARVEST FOOD SAFETY
The term `` preharvest food safety '' denotes any efforts to reduce the risk of foodborne hazards that are applied prior to harvest ( or slaughter of meat animals ) . 
The rationale for preharvest food safety in meat industries has two core premises : 
1 . 
Modification of farm ( or farm supplier ) practices can reduce the risk of foodborne hazards occurring in animals at the point of harvest . 
2 . 
This reduced risk can be sustained after harvest to the point of consumption and thereby reduce the incidence of foodborne illness 
The ecologic and epidemiologic characteristics of a given hazard determine the potential impact of preharvest interventions on consumer risk . 
Preharvest control is most effective for hazards with relatively simple epidemiology ( e.g. , limited reservoirs and modes of transmission on farms ) ; that are unable to replicate in products ; and for which the risk of post-in-tervention or ` downstream ' recontamination is negligible . 
For example , producers and their suppliers must bear the major responsibility for preventing chemical or physical hazards in animal products . 
The recent European scandals with dioxin ( Bernard and Fierens , 2002 ) and medroxprogesterone acetate ( van Leengoed et al. , 2002 ) reinforce the importance of adequate quality control systems in the supply of animal feeds , and compliance with them by all participants in industry . 
Furthermore , preharvest interventions are clearly effective for biological hazards with suitable epidemiological traits . 
The most topical example is bovine spongiform encephalopathy ( BSE ) ( Stevenson et al. , 2000 ) , and parasitic hazards in swine production are also efficiently controlled at the preharvest level ( Davies et al. , 1998 ; Gamble , 1997 ; Gamble et al. , 2001 ) . 
However , preharvest control of enteric foodborne bacteria with relatively complex ecologies ( including Salmonella , Escherichia coli , Campylobacter , Listeria , and Yersinia ) remains much more problematic and challenging ( Alban and Staerk , 2002 ; Berends et al. , 1996 ; Davies et al. , 1997 ; Sofos , 2002 ) . 
THE NATURE AND IMPACT OF PREHARVEST INTERVENTIONS
For purposes of discussion , we will categorize measures employed to manage hazards in any sector of the food supply continuum into four groups : 
1 . 
Biosecurity -- Measures to exclude the hazard from the sector 2 . 
Process management -- Systems and procedures to reduce transmission ( cross-contam-ination ) or multiplication of the hazard within the sector 3 . 
Decontamination -- Measures to destroy the hazard ( usually incorporated into the design of processes ) 4 . 
Test and removal -- Measures to detect and remove materials contaminated with the hazard . 
The relative efficacy of interventions will be determined by the epidemiology and ecology of the hazard . 
Across the entire food supply chain , the ultimate impact ( on risk to consumers ) of a locally effective intervention ( i.e. , effective at the point it is applied ) will be largely influenced by the probability of post-intervention recontamination . 
In the context of the overall food supply , the probability of `` downstream '' contamination , and the feasibility and cost of preventing it , are important considerations when evaluating potential interventions . 
We will discuss potential interventions and issues of post-inter-vention protection relevant to control of Salmo-nella in animal feed manufacturing and pork production normally involve any decontamination measures . 
One of the few studies of Salmonella con ¬ 
The appealing hypothesis that enforcement of a Salmonella-negative standard for animal feed would decrease the incidence of foodborne salmonellosis in the United States ( Crump et al. , 2002 ) invites consideration of how a negative standard might be achieved . 
Crump et al. ( 2002 ) promote the adoption of both improved process control ( institution of HACCP in the animal feed industry ) and end product testing ( Salmonella-negative standard ) in the production of animal feed . 
Use of the term `` Salmonella-negative '' rather than `` Salmo-nella-free '' conveys that those authors appreciate that verification of absolute exclusion of viable Salmonella from animal feed ( or any other matrix ) is not possible . 
Therefore , any `` Salmo-nella-negative standard '' would be a relative rather than an absolute standard , with an acceptable detection limit determined by the feed sampling protocol and the sensitivity of the testing methods employed . 
This in turn invites consideration of the acceptable limits of contamination ( detection ) that should be invoked , the points in the feed production and delivery process where contamination should be assessed , and the corrective measures that should be employed when contamination limits are exceeded . 
These issues are beyond the scope of this paper which focuses on aspects of Salmo-nella ecology and epidemiology likely to influence the impact of a Salmonella-negative standard in animal feed . 
DECONTAMINATION OF FEED DURING PROCESSING
Based on observations of Salmonella concentrations in raw feed ingredients , feed manufacturers in the EU consider that decontamination methods that deliver a 3-log reduction will `` virtually eliminate '' Salmonella from animal feed ( Cooke , 2002 ) . 
Although both physical or chemical methods can be employed to destroy bacteria in animal feed ( Cooke , 2002 ; Matlho et al. , 1997 ) , by far the most prevalent method is heat treatment , usually in conjunction with feed processing procedures such as pelleting , extrusion or roasting ( Anon , 1998 ) . 
Although it has been suggested that animal feeds should be heated to 80 -- 85 °C to destroy Salmonella ( Jones and Richardson , 2004 ; Veldman et al. , 1995 ) , heat tolerance varies among serovars , with decimal reduction times at 80 °C ( and 0.8 water activity ) ranging from approximately 2 to 12 min ( Cooke , 2002 ) . 
Because heat destruction of Sal-monella is both moisture dependent and linear over time , process-specific criteria of time and temperature are preferable to generic guidelines for temperature alone ( Coma , 2003 ; Himathongkham et al. , 1996 ) . 
Also , as Salmonella occur at low prevalence , in low numbers , and are not uniformly distributed in feed materials , Salmonella are not good candidates for monitoring the effectiveness of decontamination processes ( Veldman et al. , 1995 ) . 
Indicator organisms , particularly E. coli , have been found to be useful markers for Salmonella and are used to evaluate the effectiveness of decontamination procedures during feed processing in some countries ( Jones and Richardson , 2004 ; Veldman et al. , 1995 ) . 
Denmark imposed regulations requiring heat treatment of imported and commercial animal feeds in the early 1970s , and surveillance data indicate that the prevalence of positive feed samples ( post-processing ) is currently maintained in the range of 0.2 -- 0.5 % ( Anon , 2001 ) . 
Similarly in the Netherlands , where contaminated feed was considered the major source of animal infection in the 1960s , wide-spread use of heat treatment following good manufacturing practices has resulted in less than 1 % of commercial feed samples being positive for Salmonella ( Swanenburg , 2000 ) . 
However , because of the high volume of feed used in animal production , prevalences ( defined as the proportion of tested feed samples that are positive for Salmonella ) less than 1 % could still constitute a significant risk of infection to animals consuming the feed ( Davies et al. , 1997 ; Davis et al. , 2003 ; Harris et al. , 1997 ) . 
In this context , it is crucial to examine the relationships between qualitative ( presence vs. absence of Salmonella ) and quantitative ( concentration of organisms ) contamination of animal feed with respect to risk of animal infection and definition of acceptable levels of contamination 
Feed contamination is typically reported qualitatively as the proportion ( prevalence ) of samples that test positive ( Davis et al. , 2003 ; Harris et al. , 1997 ; Jones and Richardson , 2004 ; Lo Fo Wong , 2001 ; Notermans and Beumer , 2002 ; Veldman et al. , 1995 ) , without quantifying the concentration of organisms in contaminated materials . 
Measures of prevalence are most appropriate for discrete entities ( e.g. , proportion of individuals affected by a disease ) . 
However , this is not the case for animal feed , for which sampling is akin to sampling water from a river . 
The size ( weight or volume ) of individual aliquots is arbitrary , as is the frequency and intensity ( number of aliquots per time point ) at which test units are evaluated . 
While the published literature is laden with studies comparing laboratory methods for detecting Salmonella in a wide range of materials ( D'aoust , 1989 ; Busse , 1995 ) , the impact of sampling procedures has received relatively sparse attention ( Aho , 1992 ; Funk et al. , 2001 ) . 
However , sample weight ( volume ) and homogeneity can have a profound impact on the sensitivity for detecting Salmonella in a matrix ( Cannon and Nicholls , 2002 ; Davies et al. , 2000 ; Funk et al. , 2000 ) . 
Quantitative data ( concentration of viable organisms in feed ) are more relevant than qualitative data both biologically ( dose effects on the risk of animal infection ) and practically ( assessing the efficacy of decontamination interventions ) . 
Despite considerable innovation in diagnostic methods , enrichment culture using selective media remains the standard procedure for detection of Salmonella ( D'aoust , 1989 ; Lax et al. , 1995 ; Maciorowski et al. , 2000 ) . 
The sensitivity of enrichment methods is influenced by the relative concentrations of Salmonella bacteria and competing organisms in the source material ( Busse , 1995 ; D'aoust , 1989 ; Jameson , 1962 ) . 
Unfortunately , because enrichment culture is employed , estimation of Salmonella concentrations is reliant on most probable number ( MPN ) methods that are expensive and have considerable uncertainty ( McBride et al. , 2003 ) . 
Owing to the absence of surveillance of Sal-monella in animal feeds in the United States , qualitative data are sparse ( Crump et al. , 2002 ; Harris et al. , 1997 ; Jones and Richardson , 2004 ; McChesney et al. , 1995 ) , and published quantitative data are virtually non-existent ( Maciorowski et al. , 2000 ) . 
However , MPN values in positive samples ranged from 5 cfu/g ( limit of detection ) to 794 cfu/g ( median 128 ) in a small methodological study of animal feeds in the United States ( Maciorowski et al. , 2000 ) . 
Also , using spiked samples , these authors estimated the sensitivity of detection methods to be of the order of only 50 % for samples containing 40 organisms per gram , and that sensitivity varied among feed matrices due to variable populations of competing organisms . 
It is important to recognize that the oral infectious dose of Salmonella for chicks may be very low ( Jones and Richardson , 2004 ) , and a dose of only 48 organisms led to colonization of 50 % of chicks ( Stern et al. , 1991 ) . 
These data suggest that , at least in poultry , feed contamination at levels below the limits of reliable detection can be biologically significant . 
POST-INTERVENTION
RECONTAMINATION OF FEED: MILL TO MOUTH
For decontamination of animal feeds to be an effective tool for reducing the risk of human salmonellosis , successful elimination of contamination during feed processing must be sustained throughout feed distribution and delivery to animals . 
In the recent Salinpork project involving five European countries ( Lo Fo Wong , 2001 ) , the overall prevalence ( 6.9 % ) of contamination of feed samples collected at the point of delivery to pigs ( Germany 0 % ; Sweden 0.8 % ; Netherlands 3.5 % ; Greece 4.8 % ; Denmark 9 % ) greatly exceeded levels ( usually less than 1 % ) reported in samples from monitoring commercial feedmills ( Cooke , 2002 ; Anon , 2001 ) . 
Noting that sampling protocols differed among countries , and differences among countries other than Germany were not statistically significant , this large study suggests considerable risk of post-processing recontamination of animal feed in at least some of these countries . 
Potential points of recontamination include post-decontamination processing and handlin 
1997 ; Wegener et al. , 2003 ) . 
The authors of a recent review of these Danish programs stated that most countries are unable to apply the Swedish model , as it requires near freedom from infection in populations from the onset ( Wegener et al. , 2003 ) . 
However , based on a strategy of flock depopulation , a goal of complete freedom has been pursued in the Danish broiler industry . 
In contrast , recognizing the differing logistic constraints in the two industries and the relative difficulty of eradicating Salmonella from swine farms , the authors conclude that for pigs `` reducing the infection level should be the aim of a control strategy '' ( Wegener et al. , 2003 ) . 
As in most countries , Sal-monella is widespread among swine herds in the United States ( Anon , 1997 ; Davies et al. , 1997 ) , and the predominance of relatively large herds presents greater challenges to both the establishment and maintenance of Salmonella-free populations ( Davies and Funk , 1999 ; Wierup , 1997 ) . 
The remaining discussion will assume that in the U.S. swine industry efforts to control Salmonella in the preharvest sector would pursue a goal of reduction rather than elimination . 
OUTCOMES OF EXPOSURE TO SALMONELLA-CONTAMINATED FEED
Risk characterization ( quantifying dose-re-sponse relationships ) is a cornerstone of microbiological risk assessment ( Anon , 2003b ) . 
Dose response relationships are equally critical to assessing the risk presented by Salmonellacontaminated feed to food animal populations . 
Owing to the high contact rates among animals in most farming systems , at a population level key outcomes of exposure to contaminated feed include the duration and numbers of organisms shed by animals , as these are major determinants of the risk of secondary spread within a herd or flock . 
Although our focus is on swine , fundamental differences between the swine and broiler industries are germane to this discussion . 
In modern production systems , chicks hatch into hygienic environments designed to preclude natural exposure to adult avian intestinal flora . 
The delay in development of normal flora is thought to contribute to their high susceptibility to low oral doses of Salmonella , and is the basis for competitive exclusion strategies . 
In addition , the interval from hatching to market is approximately 6 weeks . 
A dose-response relationship in the range of 0.1 -- 0.3 organisms per gram of feed ( few birds infected ) to 100 -- 300 organisms per gram ( all birds infected ) was demonstrated using artificially contaminated feed fed over 2 to 3 weeks from `` day-old '' ( Hinton , 1988 ) . 
Although long-term fecal shedding can occur in individuals , across species the duration of fecal shedding Salmonella by most infected animals is of the order of 2 weeks to 2 months ( Berends et al. , 1996 ; Gast and Beard , 1989 ; Nielsen et al. , 1995 ) . 
Therefore , Salmonella infections of young chicks can persist until market age ( 6 weeks ) . 
It is therefore not surprising that serovars isolated from feedmills and on carcasses have been correlated in some studies of poultry production ( Corry et al. , 2002 ) , and feed may be a major source of infection in that industry ( Jones and Richardson , 2004 ) . 
Unlike commercially hatched chicks , neonatal pigs are exposed from the time of birth to the intestinal flora of the sow . 
Age-susceptibil-ity of pigs to oral infection with Salmonella has not been closely studied , but is likely to be of minimal epidemiologic importance . 
Firstly , unlike newly hatched chicks , suckling piglets have negligible direct exposure to solid feed until weaning ( approximately 3 weeks ) , by which time the intestinal flora are relatively well developed . 
Secondly , due to the 6-month interval from birth to harvest , Salmonella infections of neonatal pigs are unlikely to persist to market age . 
Epidemiologic studies of Sal-monella in several countries indicate that infection of pigs early in life is a minor contributor to the risk of Salmonella infection in market age pigs , and that infection closer to the point of harvest ( 6 months of age ) is of overriding importance ( Beloeil et al. , 2003 ; Berends et al. , 1996 ; Davies et al. , 1998 ; Funk et al. , 2001 ; Korsak et al. , 2003 ; Kranker et al. , 2003 ; van der Wolf et al. , 2001 ) . 
Both the establishment and persistence of Salmonella infections of swine are influenced by dose and route of exposure ( Gray et al. , 1996 ) . 
In contrast to the low doses that are sufficien to infect day-old chicks orally , exposure doses of 103 Salmonella organisms given intranasally or orally were insufficient to establish infections in pigs ( Fedorka-Cray et al. , 1995 ; Gray et al. , 1995 ) . 
Experimental studies in pigs have tended to employ much higher exposures ( 103 to 1011 ) than in poultry ( Craven et al. , 2000 ; Fe-dorka-Cray et al. , 1995 ; Gray et al. , 1995 , 1996 ; Proux et al. , 2001 ; Wood et al. , 1989 ) , and oral doses of 108cfu have been necessary to reliably achieve infection ( Anderson et al. , 1998 ) . 
Assuming daily feed consumption of 3 kg for a market pig within 2 months before harvest , concentrations greater than 104 Salmonella per gram of feed would be required to deliver this dose in one day . 
Furthermore , Salmonella serovars vary markedly with respect to infectivity for pigs and likelihood of secondary transmission to other animals . 
While oral exposure to 5 108 cfu S. Typhimurium or S. Livingstone administered in 25 g of feed led to persistent infection of challenged pigs and their pen mates , persistent infections did not result in pen mates of pigs exposed to equal doses of S. Gold coast or S. Panama ( van Winsen et al. , 2001 ) . 
This phenomenon of biological diversity among serovars , including the inability of many serovars to establish persistent infection in pigs following exposure via feed , was described in some of the earliest studies conducted ( Smith , 1960 ) . 
Marked diversity of Salmonella serovars is typically reported in surveys of feed contamination , and serovars of greatest epidemiological significance to human health ( S. Typhimurium , S. Enteritidis ) have been conspicuously sparse among isolates from feed ( Bisping , 1993 ; Davies et al. , 1997 ; Funk et al. , 2001 ; Harris et al. , 1997 ; Murray , 1994 ; Jones and Richardson , 2004 ; Notermans and Beumer , 2002 ; Stege , 2000 ; Veldman et al. , 1995 ) . 
These observations support the contention that many Salmonella serovars occurring in animal feed are of negligible epidemiological significance from the standpoint of foodborne disease risk . 
While variability in infectivity among serovars could explain much of the consistent disparity between Salmonella serovars isolated from feed and pigs ( Davies et al. , 1997 ; Funk et al. , 2001 ; Korsak et al. , 2003 ; Stege , 2000 ) , a more influential factor may be the incidence of infection from non-feed sources . 
NON-FEED SOURCES OF SALMONELLA INFECTION
The complexity of the epidemiology of Sal-monella is difficult to overstate , and the predominant sources of infection are likely to vary among farms and over time . 
Based on review of a considerable body of swine research in The Netherlands , Berends et al. ( 1996 ) concluded that `` the role of on-farm contamination cycles is so important that the role of other factors is difficult to ascertain '' ( Berends et al. , 1996 ) . 
Similarly , recent research in North America attests to the complexity of contamination of swine farm environments ( Barber et al. , 2002 ; Carlson and Blaha , 2001 ; Funk et al. , 2001 ; Letellier et al. , 1999 ) . 
In contrast to the apparently high doses of Salmonella required to infect pigs orally in feed , transmission of Salmo-nella to pigs has been readily achieved by contact exposure to fecal materials containing 103 organisms per gram ( Gray et al. , 1996 ; Hurd et al. , 2001 ) . 
These authors concluded that relatively small numbers of pigs shedding modest numbers of Salmonella can lead to rapid transmission and infection among many swine , supporting the contention that infected pigs are the most important reservoir of infection on swine farms ( Berends et al. , 1996 ; Davies et al. , 1997 ; Wierup , 1997 ) . 
Clearly other animal reservoirs ( wild birds , pets , rodents and insects ) in the farm environment that can contaminate stored feed may also be direct sources of exposure of pigs ( Barber et al. , 2002 ; Craven et al. , 2000 ; Davies and Breslin , 2002a , b ) . 
Unfortunately , there are few longitudinal studies incorporating detailed sampling of both pigs and feed . 
A detailed 2-year investigation of two modern multiple-site production systems in North Carolina ( including separated breeding , nursery and finishing farms ) pointed to an insignificant role of feed contamination . 
Only 0.25 % of 800 feed samples ( collected from feeders in barns ) were positive for Salmonella , while much higher proportions of pig fecal samples and environmental samples ( floor samples taken after cleaning of buildings ) were culture positive ( Funk et al. , 2001 ) . 
Widespread contamination of farm environmental compartments was also found in an Illinois study in which none of 221 feed samples were cultur positive ( Barber et al. , 2002 ) . 
Similarly , a large international study in Europe reported no correlation between contamination of feed and Salmonella seroprevalence ( Lo Fo Wong , 2001 ) . 
In that study , the most extensive investigations were conducted in Denmark , where numerous serovars were isolated from feed but not from pigs consuming the feed ( Stege , 2000 ) . 
Salmo-nella Typhimurium , the serovar that is most prevalent in pigs and second most prevalent in people in Denmark , was only isolated from feed samples on farms where fecal contamination of the feed could have occurred ( Stege , 2000 ) . 
Although there is no question about the historic importance of animal feed as a vehicle for geographical dissemination of Salmonella among countries and farms ( Crump et al. , 2002 ) , recent epidemiological studies in swine production indicate minor importance of contaminated feed on farms where Salmonella are established . 
CONTAMINATION BEYOND THE FARM
Thus far we have presented some evidence why a strategy to reduce the risk of human sal-monellosis by eliminating Salmonella from commercial animal feed might be negated by recontamination of feed or overwhelmed by infections from non-feed sources . 
These concerns are compounded by further risks of recontamination beyond the farm gate . 
The potential for Salmonella infections during lairage ( holding in pens prior to harvest ) to make a major contribution to risk of carcass contamination was recognized over 40 years ago in studies in the United States ( Newell and Williams , Jr. , 1971 ) , and has been consistently reiterated by recent work in this country and elsewhere ( Gebreyes et al. , 2004 ; Hurd et al. , 2001 , 2002 ; Korsak et al. , 2003 ; Rostagno et al. , 2003 ; Swanenburg et al. , 2001 ) . 
In some studies , the magnitudes of the increases in prevalence between farm and slaughter have been striking , and Swanenburg estimated that 75 % and 25 % of carcass contamination derived from lairage infection of pigs from seronegative ( implying little on-farm exposure ) and seropositive herds , respectively ( Swanenburg , 2000 ) . 
While there is little question that most lairage contamination originates from farms , substantial risk of Salmonella exposure during lairage can negate the gains from preharvest efforts to reduce Salmonella on farms . 
Even if regulation of commercial animal feed could enable production of Salmonella-free pigs , to preserve this advantage these animals would need to be channeled through separate facilities from animals produced on farms that use home-mixed feed . 
Clearly , further potential for Salmonella contamination of ( or multiplication on ) meat products persists throughout the food supply chain until the point of consumption . 
A microbiological study of the pork supply chain in Korea indicated that inadequate temperature control during transport and merchandising of pork products made a major contribution to the contamination of pork products offered to consumers in that country ( Rho et al. , 2001 ) . 
The apparently high incidence of foodborne disease caused by agents ( particularly viruses , but also bacteria ) with no known animal reservoir tells us that the risk of introduction of pathogens ( including zoonotic foodborne pathogens ) by and from humans involved in food production and preparation could be substantial ( Cherubin , 1981 ; Koopmans and Duizer , 2004 ; Mead et al. , 1999 ) . 
Despite the unquestioned preeminence of foodborne exposures in human salmonellosis , with the exception of milk and eggs outbreaks implicating fresh rather than processed animal products have been relatively uncommon . 
Risks of contamination during processing , distribution and preparation of food are probably significant ( Cherubin , 1981 ; Reij and den Aantrekker , 2004 ) . 
The use of molecular subtyping has enhanced the power to detect common source outbreaks of Salmonella which may previously have gone unnoticed . 
Further investigation of these outbreaks commonly implicated infected food handlers and person-to-person transmission ( Bender et al. , 2001 ) . 
Although less common in modern times , foodborne salmonellosis due to S. Typhi ( host adapted to humans with no animal reservoir ) continues to occur and in most outbreaks infected humans were the source of food contamination ( Olsen et al. , 2003 ) . 
Risk of recontamination of foods through the processing , distribution , and preparation phases of the food continuum is poorly understood and warrants more attention ( Reij and den Aantrekker , 2004 ) . 
The low concordance between Salmonella serovars isolated from human salmonellosis cases and from food animals or carcasses ( Sarwari et al. , 2001 ; Schlosser et al. , 2000 ; Sumner et al. , 2004 ; van Leengoed et al. , 2002 ) mirrors that described earlier between serovars from pigs and their feed . 
This lack of concordance may be attributable to variability in infectivity among different Salmonella serovars across host species ( animal and human ) ( Crump et al. , 2002 ; Sarwari et al. , 2001 ; Schlosser et al. , 2000 ) or dose effects ( Schlosser et al. , 2000 ) ; post-harvest recontamination of animal food products ( Bender et al. , 2001 ; Cherubin , 1981 ; Reij and den Aantrekker , 2004 ) ; infections from sources other than food animal products ( Crump et al. , 2002 ; Sarwari et al. , 2001 ; Schlosser et al. , 2000 ; Sumner et al. , 2004 ) and differential handling of animal food products by consumers based on perceptions of risk ( Schlosser et al. , 2000 ) . 
Causal inference from such ecological data is speculative at best , and contrasting perspectives can be supported through selective emphasis among these putative mechanisms . 
There is little question that non-host-adapted serovars of Salmonella are not epidemiologically homogeneous ( Cherubin , 1981 ) . 
Perhaps the most convincing example is S. Sofia in Australia , which emerged to be the predominant serovar on chicken carcasses ( up to 80 % of isolates ) , while the organism was never detected in meat products of other species and remained very rare among human cases ( Harrington et al. , 1991 ; Sumner et al. , 2004 ) . 
The predominance of S. Derby among isolates from swine in the United States over several decades ( Davies et al. , 1997 ; Sarwari et al. , 2004 ; Schlosser et al. , 2000 ; Sorensen , 1992 ) , while remaining a relatively uncommon serovar among human cases or other food animals or meat products ( Sarwari et al. , 2001 ) , could reflect low infectivity of this serovar in humans or the relative insignificance of pork as a vehicle for human salmo-nellosis in this country . 
The case for the likely importance of `` downstream '' sources of contamination of animal products also gains circumstantial support in the wake of regulatory changes in the Australian meat and poultry industries . 
Subsequent to these changes , measurable improvements in the microbiological status of meat and poultry products have occurred but have not translated into lower incidence of human salmonellosis ( Sumner et al. , 2004 ) . 
However , there are several plausible mechanism that may explain this . 
These include measurement error in reported disease statistics , and the fact that temporal patterns from monitoring contamination of animal carcasses may not represent changes in the collective contamination of products derived from them . 
In contrast , a marked decline in reported rates of human salmonellosis in the United States preceded the implementation of regulatory changes in meat industries in 1996 ( Olsen et al. , 2001 ) . 
In that report , the authors postulated that the decline was attributable to improved standards in meat industries in anticipation of the regulatory changes . 
However , it is equally plausible that the high profile of food safety in the popular media during this period prompted increased diligence in food preparation both inside and outside the home . 
These examples ( Sumner et al. , 2004 ; Olsen et al. , 2001 ) illustrate the difficulties in demonstrating public health benefits from `` upstream '' interventions in a complex food supply system . 
They also reiterate the uncertainties of causal inference from temporal ecological data , and explanations of temporal trends are readily colored by ones perspectives . 
Failure to account for non-foodborne routes of infection , as well as overestimation of the degree of foodborne disease derived from the animal production sector are likely to result in biased inferences in risk analyses of food related diseases ( Barber et al. , 2003 ) . 
CONCLUSION
Food animal producers have ethical obligations to reduce the risk of foodborne hazards in animals under their care . 
Animal feed is one of numerous potential sources of animal and human infection with Salmonella ( Crump et al. , 2002 ) . 
However , achieving and assuring adequate decontamination of animal feed is problematic , and a substantial body of research points to a minor role of feed contamination i the epidemiology of Salmonella in U.S. pork production . 
Therefore the theoretical benefits that this approach promises may prove difficult to realize . 
Putative preharvest interventions for Salmonella control in pork production have been based more on first principles and opinion than on empirical evidence ( Berends et al. , 1996 ; Davies and Funk , 1999 ; Lo Fo Wong et al. , 2002 ) . 
As such , uncertainty remains about their efficacy and more systematic evaluations of putative preharvest interventions are required under commercial conditions . 
Even if interventions are effective at the preharvest level , their ultimate impact on the incidence of human salmonellosis remains uncertain due to the subsequent risks of recontamination of animals , carcasses or food products . 
The paucity of current and representative data of the extent of Salmonella contamination of animal feed in the United States invites a structured survey of the animal feed industry . 
This is necessary to enable more informed debate on the feasibility and likely efficacy of enforcing a Salmonella-negative standard for animal feeds to reduce the incidence of human salmonellosis . 
ACKNOWLEDGMENTS
We wish to thank Dr. Steve Dritz , Kansas State University , and Dr. Don Franco for their constructive comments on the manuscript .