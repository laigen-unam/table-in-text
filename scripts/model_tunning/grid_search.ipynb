{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer,classification_report\n",
    "\n",
    "\n",
    "\n",
    "def classificator_score(clasificador, entrenamiento,y_test):\n",
    "    print('Best parameters:\\n')\n",
    "    best_parameters = clasificador.best_estimator_.get_params()\n",
    "    for param in sorted(best_parameters.keys()):\n",
    "        print((param, best_parameters[param]))\n",
    "    prediction = clasificador.predict(entrenamiento)\n",
    "    matew = matthews_corrcoef(y_test, prediction)\n",
    "    print('Matthews correlation coefficienr:', matew)\n",
    "    #print(\"Confusion Matrix: \\n \", confusion_matrix(y_test, prediction))\n",
    "    return prediction\n",
    "\n",
    "def preporcessing_data(type_analyzer,ngram_size,feature_chosed):\n",
    "    postables_local = open(\"../dataset/TablesPOS.txt\").readlines()\n",
    "    possentenes_local = open(\"../dataset/NoTablesPOS.txt\").readlines()\n",
    "    poscomplete_local = postables_local + possentenes_local\n",
    "\n",
    "    if feature_chosed != ['all']:\n",
    "        new_sentence = []\n",
    "        for sentence_num in range(len(poscomplete_local)):\n",
    "            tokens = poscomplete_local[sentence_num].split(' ')\n",
    "            new_words = []\n",
    "            for word_num in tokens:\n",
    "                if word_num in feature_chosed:\n",
    "                    new_words.append(word_num)\n",
    "            new_sentence.append(' '.join(new_words))\n",
    "    else:\n",
    "        new_sentence = poscomplete_local\n",
    "\n",
    "\n",
    "    class_label_local = []\n",
    "    for i in range(len(new_sentence)):\n",
    "        if i < len(postables_local):\n",
    "            class_label_local.append('TABLES')\n",
    "        else:\n",
    "            class_label_local.append('NONE TABLES')\n",
    "\n",
    "    fun_x_train, fun_x_test, fun_y_train, fun_y_test = train_test_split(new_sentence, class_label_local, train_size=0.80, test_size=0.20)\n",
    "\n",
    "    tdifvectorizer = TfidfVectorizer(analyzer = type_analyzer,ngram_range=ngram_size)\n",
    "    x_train_fun = tdifvectorizer.fit_transform(fun_x_train)\n",
    "    x_test_fun = tdifvectorizer.transform(fun_x_test)\n",
    "\n",
    "    variance_selector = VarianceThreshold()\n",
    "    variance_selector = variance_selector.fit(x_train_fun,x_test_fun)\n",
    "    x_train_fun = variance_selector.transform(x_train_fun)\n",
    "    x_test_fun = variance_selector.transform(x_test_fun)\n",
    "\n",
    "    return  x_train_fun, x_test_fun, fun_y_train, fun_y_test\n",
    "\n",
    "def run_classifier_grid(x_train, x_test, y_train, y_test ,scorer_fun):\n",
    "    f1scores = []\n",
    "    mathewscores = []\n",
    "    print(\"\\n----------------------------------- Random Forest -----------------------------------------\")\n",
    "    rand_forest_classifier = RandomForestClassifier()\n",
    "    rand_forest_param_grid = {'n_estimators': [100, 150,200,300],\n",
    "                            'bootstrap': [True, False],\n",
    "                            'criterion': [\"gini\", \"entropy\"],\n",
    "                            'class_weight': ['balanced', None]}\n",
    "\n",
    "    random_forest = model_selection.RandomizedSearchCV(rand_forest_classifier, rand_forest_param_grid,cv=crossV, n_jobs=jobs,scoring=scorer_fun, verbose = 0)\n",
    "    random_forest.fit(x_train, y_train)\n",
    "    rand_forest_predict = classificator_score(random_forest, x_test,y_test)\n",
    "    score = f1_score(y_test, rand_forest_predict, pos_label='TABLES', average='binary')\n",
    "    matw = matthews_corrcoef(y_test, rand_forest_predict)\n",
    "    f1scores.append(score)\n",
    "    mathewscores.append(matw)\n",
    "    print(classification_report(y_test, rand_forest_predict))\n",
    "\n",
    "\n",
    "    print(\"\\n----------------------------------- SGDClassifier  -----------------------------------------\")\n",
    "    sgdc_classifier = SGDClassifier(loss = 'log_loss')\n",
    "    sgdc_param_grid = {'alpha' : [10**(-x) for x in range(7)],\n",
    "                        'penalty' : ['elasticnet', 'l1', 'l2'],\n",
    "                        'l1_ratio' : [0.15, 0.25, 0.5, 0.75],\n",
    "                        'class_weight': ['balanced', None],}\n",
    "\n",
    "    sgdc_model = model_selection.RandomizedSearchCV(sgdc_classifier, sgdc_param_grid,cv=crossV,n_iter=50, n_jobs=jobs,scoring=scorer_fun,  verbose = 0)\n",
    "    sgdc_model.fit(x_train, y_train)\n",
    "    sgdc_predict = classificator_score(sgdc_model, x_test, y_test)\n",
    "    score = f1_score(y_test, sgdc_predict, pos_label='TABLES', average='binary')\n",
    "    matw = matthews_corrcoef(y_test, sgdc_predict)\n",
    "    f1scores.append(score)\n",
    "    mathewscores.append(matw)\n",
    "    print(classification_report(y_test, sgdc_predict))\n",
    "\n",
    "    print(\"\\n-------------------- Radial Basis Function Support Vector Machine  --------------------\")\n",
    "    svm = SVC()\n",
    "    svm_param_grid = {'C': np.arange(1,50,0.5),\n",
    "                             'gamma': np.arange(0.01,1.01,0.1),\n",
    "                             'kernel': ['rbf'], 'class_weight': ['balanced', None],}\n",
    "\n",
    "    # The number of iterations was reduced in this example in order to save computational time,\n",
    "    svm_rbf = model_selection.RandomizedSearchCV(svm, svm_param_grid, n_iter=70,cv=crossV, n_jobs=-1, scoring=scorer_fun, verbose = 0)\n",
    "    svm_rbf.fit(x_train, y_train)\n",
    "    svm_predict = classificator_score(svm_rbf, x_test, y_test)\n",
    "    score = f1_score(y_test, svm_predict, pos_label='TABLES', average='binary')\n",
    "    matw = matthews_corrcoef(y_test, svm_predict)\n",
    "    f1scores.append(score)\n",
    "    mathewscores.append(matw)\n",
    "    print(classification_report(y_test, svm_predict))\n",
    "    return f1scores, mathewscores\n",
    "\n",
    "run = 0\n",
    "jobs = -1\n",
    "crossV = 5\n",
    "all_matew = {}\n",
    "all_scores = {}\n",
    "\n",
    "vectorization = ['word','char']\n",
    "feature_selection =  ['None',70,90]\n",
    "type_scorer = ['weighted', 'binary']\n",
    "n_gram_range = {'word':[(1,1),(2,2),(3,3),(1,2),(2,3),(1,3)],'char':[(2,3),(2,4),(2,5),(3,4),(3,5)]}\n",
    "feature_type = {'all_pos':['all'],\n",
    "                'symbols': [',', '.', ':', 'LRB', 'RRB', 'LCB', 'RCB', 'SYM', 'HYPH', 'NFP'],\n",
    "                'numbers':['CD'],\n",
    "                'symbols_numbers': [',', '.', ':', 'LRB', 'RRB', 'LCB', 'RCB', 'SYM', 'HYPH', 'NFP','CD']}\n",
    "\n",
    "\n",
    "for analyzer in vectorization:\n",
    "    for ngram in n_gram_range[analyzer]:\n",
    "        for scorer in type_scorer:\n",
    "\n",
    "            if scorer == 'weighted':\n",
    "                run_scorer = make_scorer(f1_score, average='weighted')\n",
    "            else:\n",
    "                run_scorer = make_scorer(f1_score, labels=['NONE TABLES','TABLES'],\n",
    "                                         average = 'binary',pos_label = 'TABLES')\n",
    "\n",
    "            for feature in feature_type.keys():\n",
    "                which_features = feature_type[feature]\n",
    "                x_train_ds, x_test_ds, y_train_labels, y_test_labels = preporcessing_data(analyzer,ngram,which_features)\n",
    "\n",
    "                for selection in feature_selection:\n",
    "                    run += 1\n",
    "                    if (selection != 'None') and (feature == 'all_pos'):\n",
    "                        selector = SelectPercentile(chi2,percentile=selection)\n",
    "                        x_train_ds = selector.fit_transform(x_train_ds,y_train_labels)\n",
    "                        x_test_ds = selector.transform(x_test_ds)\n",
    "\n",
    "\n",
    "                    score_f1,score_mathew = run_classifier_grid(x_train_ds, x_test_ds, y_train_labels, y_test_labels, run_scorer)\n",
    "                    print(f'Run #{run}')\n",
    "                    print(f'F1 Score: {score_f1}')\n",
    "                    print(f'Matthews Correlation: {score_mathew}')\n",
    "                    print('Vectorization: ',analyzer,'\\nN-gram range: ',ngram,'\\nScorer: ',scorer,'\\nSelected features',feature,'\\nFeature selection',selection,'\\nOversampling: None')\n",
    "                    print('########################################################\\n\\n')\n",
    "                    all_scores[f'Run{run}_f1'] = score_f1\n",
    "                    all_matew[f'Run{run}_Matthew'] = score_mathew\n",
    "\n",
    "                    if scorer != 'weighted':\n",
    "                        run += 1\n",
    "                        oversampling = RandomOverSampler()\n",
    "                        x_train_ds,y_train_labels = oversampling.fit_resample(x_train_ds,y_train_labels)\n",
    "                        score_f1,score_mathew = run_classifier_grid(x_train_ds, x_test_ds, y_train_labels, y_test_labels, run_scorer)\n",
    "                        print('Vectorization: ',analyzer,'\\nN-gram range: ',ngram,'\\nScorer: ',scorer,'\\nSelected features',feature,'\\nFeature selection',selection,'\\nOversampling: Yes')\n",
    "                        print('########################################################\\n\\n')\n",
    "                        all_scores[f'Run{run}_f1'] = score_f1\n",
    "                        all_matew[f'Run{run}_Matthew'] = score_mathew\n",
    "\n",
    "\n",
    "mathew = pd.DataFrame.from_dict(all_matew)\n",
    "f1 = pd.DataFrame.from_dict(all_scores)\n",
    "\n",
    "f1.to_csv('../f1_table')\n",
    "mathew.to_csv('../matthew_table')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51256fb29d3417d51258ec6b95047b6f4277a1591b5c1cc3248ea847bb42ce8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
